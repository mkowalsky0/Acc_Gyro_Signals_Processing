<h1>
The Inertial Sensor Signals Processing
<img src="https://media.giphy.com/media/ClI4dtCC0E9AZsAVss/giphy.gif" width="40px">
</h1>

- this project is based on [*Smartphone-Based Recognition of Human Activities and Postural Transitions Data Set*](http://archive.ics.uci.edu/ml/datasets/smartphone-based+recognition+of+human+activities+and+postural+transitions) :point_left: all descriptions are here
- includes the use of csv files, data processing algorithms, windowing, time and frequency signals, data visualisation
- final data is ready to use in *Neural Network Models*
- the project is focused on the classification of 6 activities: 3 dynamic like walking, walking upstairs, walking downstairs, and 3 static like standing, sitting, laying
- data was registered by sensors from smartphone

<h1>
Technologies
<img src="https://media.giphy.com/media/Vf3ZKdillTMOOaOho0/giphy.gif" width="30px">
</h1>

- language: Python 3.10.1
- main libraries: TensorFlow, Keras, Matplotlib, Seaborn, Pandas, Numpy
- computing platform: Jupyter Notebook

<h1>
More about the project
<img src="https://media.giphy.com/media/KjDrmapQOXwK4r4gqZ/giphy.gif" width="30px">
</h1>

- all data samples and labels are saved in DataFrames
